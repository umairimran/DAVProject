{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from fancyimpute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12420\\2839501798.py:1: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  ecomonic_df=pd.read_csv('worldBankData\\economicData.csv')\n"
     ]
    }
   ],
   "source": [
    "ecomonic_df=pd.read_csv('worldBankData\\economicData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=ecomonic_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "encoder=LabelEncoder()\n",
    "df['Country Name']=encoder.fit_transform(df['Country Name'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "df_not_to_scale=df[['Country Name','who_region','world_bank_income_level','Year']]\n",
    "df=scaler.fit_transform(df.drop(['Country Name','who_region','world_bank_income_level','Year'],axis=1))\n",
    "df=pd.DataFrame(df,columns=ecomonic_df.columns[4:])\n",
    "df=pd.concat([df_not_to_scale,df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling Nulls for the columns \"Adjusted net national income (annual % growth)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fancyimpute import IterativeImputer\n",
    "\n",
    "def impute_all_columns(df):\n",
    "    columns_to_impute = df.columns[4:]  \n",
    "    imputer = IterativeImputer()\n",
    "    df[columns_to_impute] = imputer.fit_transform(df[columns_to_impute])\n",
    "    return df\n",
    "\n",
    "print(\"Before imputation:\", df.shape)\n",
    "\n",
    "df = impute_all_columns(df)\n",
    "\n",
    "print(\"After imputation:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Only process 'economicData.csv'\u001b[39;00m\n\u001b[0;32m     41\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworldBankData/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 42\u001b[0m \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meconomicData.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 33\u001b[0m, in \u001b[0;36mprocess_file\u001b[1;34m(file, base_dir)\u001b[0m\n\u001b[0;32m     30\u001b[0m columns_with_missing \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_to_use \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39many()]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Use joblib to parallelize the imputation process for columns with missing values\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimpute_column\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_to_use\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns_with_missing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# After all columns are processed, save the file with imputed values\u001b[39;00m\n\u001b[0;32m     36\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Last returned value after processing all columns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\Desktop\\health_care_ML_project\\env\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\Desktop\\health_care_ML_project\\env\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\Desktop\\health_care_ML_project\\env\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def impute_column(df, column, columns_to_use):\n",
    "\n",
    "    X = df[columns_to_use].drop(columns=[column], errors='ignore')\n",
    "    y = df[column]\n",
    "\n",
    "\n",
    "    X = X[y.notna()]\n",
    "    y = y.dropna()\n",
    "\n",
    " \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)  # Use multiple cores\n",
    "    model.fit(X, y)\n",
    "\n",
    "\n",
    "    missing_rows = df[column].isnull()\n",
    "    df.loc[missing_rows, column] = model.predict(df.loc[missing_rows, columns_to_use].drop(columns=[column], errors='ignore'))\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_file(file, base_dir):\n",
    "    df = pd.read_csv(base_dir + file)\n",
    "\n",
    "    columns_to_use = df.columns[4:]  \n",
    "    columns_with_missing = [col for col in columns_to_use if df[col].isnull().any()]\n",
    "\n",
    "    df = Parallel(n_jobs=-1)(delayed(impute_column)(df, column, columns_to_use) for column in columns_with_missing)\n",
    "\n",
    "    df = df[-1]  \n",
    "    df.to_csv(base_dir + 'imputed_' + file, index=False)\n",
    "    print(f\"Done processing {file}\") \n",
    "\n",
    "base_dir = 'worldBankData/'\n",
    "process_file('economicData.csv', base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_700\\3456981994.py:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  df=pd.read_csv('worldBankData\\imputed_social.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Country Name                                                                                        0\n",
       "who_region                                                                                          0\n",
       "world_bank_income_level                                                                             0\n",
       "Year                                                                                                0\n",
       "Women Business and the Law Index Score (scale 1-100)                                                0\n",
       "                                                                                                   ..\n",
       "People with basic handwashing facilities including soap and water, urban (% of urban population)    0\n",
       "Permanent cropland (% of land area)                                                                 0\n",
       "Individuals using the Internet (% of population)                                                    0\n",
       "Individuals using the Internet, female (% of female population)                                     0\n",
       "Individuals using the Internet, male (% of male population)                                         0\n",
       "Length: 128, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('worldBankData\\imputed_social.csv')\n",
    "df.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
